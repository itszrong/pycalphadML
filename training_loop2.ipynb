{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.losses import mean_squared_error\n",
    "from tensorflow.keras import Model, optimizers\n",
    "\n",
    "X = tf.random.shuffle(np.random.normal(size=500).reshape(-1,10,1))\n",
    "# Train_X = X[:30]\n",
    "# Val_X = X[30:40]\n",
    "# Test_X = X[40:50]\n",
    "# Y = 2*X + 2\n",
    "# Train_Y = Y[:30]\n",
    "# Val_Y = Y[30:40]\n",
    "# Test_Y = Y[40:50]\n",
    "\n",
    "x_train = np.load('x_train.npy')\n",
    "x_test = np.load('x_test.npy')\n",
    "y_train = np.load('y_train.npy')\n",
    "y_test = np.load('y_test.npy')\n",
    "\n",
    "Train_X = x_train\n",
    "Train_Y = y_train\n",
    "Val_x = x_test\n",
    "Val_Y = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs = tf.keras.Input(shape=(1,))\n",
    "# x = Dense(2, activation=\"relu\", name=\"dense_1\")(inputs)\n",
    "# x = Dense(2, activation=\"relu\", name=\"dense_2\")(x)\n",
    "# outputs = Dense(1, name=\"predictions\")(x)\n",
    "# model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "optimizer = optimizers.SGD(learning_rate=1e-3)\n",
    "loss_fn =mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from getvalues import get_values\n",
    "from neural import CalphadPhaseModel\n",
    "from turtle import shape\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow_addons.layers import PolynomialCrossing\n",
    "from keras.layers import Conv1D\n",
    "from keras.optimizers import Optimizer\n",
    "import pycalphad\n",
    "from pycalphad import Database, calculate, variables as v\n",
    "phase_name = 'liquid'\n",
    "dbf = Database('Mg_Si_Zn.tdb')\n",
    "comps = ['MG', 'SI', 'ZN', 'VA']\n",
    "epochs_per_run = 1\n",
    "mod = pycalphad.Model(dbf, comps, phase_name)\n",
    "sublattice_dof = [len(t) for t in mod.constituents]\n",
    "temp_scale = x_train[:, 0].max()\n",
    "energy_scale = y_train.std()\n",
    "model = CalphadPhaseModel(sublattice_dof, mod.site_ratios, name=phase_name,\n",
    "                                 temp_scale=temp_scale, energy_scale=energy_scale)\n",
    "model.compile(optimizer='adam', loss='mae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "batch_size_train = 100\n",
    "batch_size_val = 20\n",
    "\n",
    "def fetch_batch(X, y, batch_size, batch):\n",
    "    start = batch*batch_size\n",
    "    \n",
    "    X_batch = X[start:start+batch_size, :]\n",
    "    y_batch = y[start:start+batch_size]\n",
    "    \n",
    "    return X_batch, y_batch\n",
    "\n",
    "batch = 1\n",
    "\n",
    "X, y = shuffle(x_train, y_train, random_state = 42)\n",
    "X_batch, y_batch = fetch_batch(X, y, batch_size_train, batch)\n",
    "\n",
    "Val_X_batch, Val_y_batch = shuffle(x_test, y_test, random_state = 42)\n",
    "Val_X_batch, Val_y_batch = fetch_batch(Val_X_batch, Val_y_batch, batch_size_val, batch)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 4) (100,)\n",
      "(20, 4) (20,)\n"
     ]
    }
   ],
   "source": [
    "print(X_batch.shape, y_batch.shape)\n",
    "print(Val_X_batch.shape, Val_y_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss(x, y, model, get_values, dbf, comps):\n",
    "    with tf.GradientTape(persistent=True) as tape:\n",
    "        # print(step)\n",
    "        x = x[np.newaxis].T\n",
    "        entropy = get_values('SM', 'LIQUID', x.T, dbf, comps)\n",
    "        entropy = tf.convert_to_tensor(entropy, dtype=tf.float32)\n",
    "\n",
    "        x_tensor = tf.convert_to_tensor(x, dtype=tf.float32)\n",
    "        y_tensor = tf.convert_to_tensor(y, dtype=tf.float32)\n",
    "        tape.watch(x_tensor)\n",
    "        predictions = model(x_tensor, training=True)\n",
    "        # print(predictions)\n",
    "        dy_dx = tape.gradient(predictions, x_tensor)\n",
    "        # print(dy_dx)\n",
    "\n",
    "        RMSE_loss = tf.sqrt(tf.divide(tf.reduce_sum(tf.pow(tf.subtract(predictions, y_tensor),2.0)),tf.cast(tf.size(y_tensor), tf.float32))) \n",
    "        derivative_loss = tf.add(entropy, sum(dy_dx))\n",
    "        loss_value = tf.add(RMSE_loss, derivative_loss)\n",
    "    return loss_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optimizers.SGD(learning_rate=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    loss_array = []\n",
    "    val_loss_array = []\n",
    "    \n",
    "    for step, (x_batch_train, y_batch_train) in enumerate(zip(X_batch, y_batch)):\n",
    "        \n",
    "        with tf.GradientTape(persistent=True) as tape:\n",
    "            # print(step)\n",
    "            x_batch_train = x_batch_train[np.newaxis].T\n",
    "            entropy = get_values('SM', 'LIQUID', x_batch_train.T, dbf, comps)\n",
    "            entropy = tf.convert_to_tensor(entropy, dtype=tf.float32)\n",
    "\n",
    "            x_tensor = tf.convert_to_tensor(x_batch_train, dtype=tf.float32)\n",
    "            y_tensor = tf.convert_to_tensor(y_batch_train, dtype=tf.float32)\n",
    "            tape.watch(x_tensor)\n",
    "            # print(x_tensor)\n",
    "            predictions = model(x_tensor, training=True)\n",
    "            # print(predictions)\n",
    "\n",
    "            dy_dx = tape.gradient(predictions, x_tensor)\n",
    "\n",
    "            RMSE_loss = tf.sqrt(tf.divide(tf.reduce_sum(tf.pow(tf.subtract(predictions, y_tensor),2.0)),tf.cast(tf.size(y_tensor), tf.float32))) \n",
    "            derivative_loss = tf.add(entropy, sum(dy_dx))\n",
    "            # print('Loss', tf.get_static_value(RMSE_loss), tf.get_static_value(derivative_loss))\n",
    "            loss_value = tf.add(RMSE_loss, derivative_loss)\n",
    "            # print(loss_value)\n",
    "            loss_array.append(loss_value)\n",
    "\n",
    "            grads = tape.gradient(loss_value, model.trainable_variables)\n",
    "            optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "    #print(grads)\n",
    "    # print('Epoch: ', epoch+1,' Average Train loss:', tf.get_static_value(sum(loss_array)/len(loss_array)))\n",
    "\n",
    "    for step, (x_batch_val, y_batch_val) in enumerate(zip(Val_X_batch, Val_y_batch)):\n",
    "        # val_predictions = model(x_batch_val, training=False)\n",
    "        # print('Valuation predictions for the batch :')\n",
    "        # print(val_predictions)\n",
    "        # print('Actual Valuation for the batch :')\n",
    "        # print(y_batch_val)\n",
    "        # print('x_batch_val', x_batch_val)\n",
    "        x, y = x_batch_val, y_batch_val\n",
    "        val_loss_value = get_loss(x, y, model, get_values, dbf, comps)\n",
    "        val_loss_array.append(val_loss_value)\n",
    "\n",
    "        # y_batch_val = tf.cast(y_batch_val, tf.float32)\n",
    "        # RMSE_loss = tf.sqrt(tf.divide(tf.reduce_sum(tf.pow(tf.subtract(predictions, y_tensor),2.0)),tf.cast(tf.size(y_tensor), tf.float32))) \n",
    "        # derivative_loss = tf.add(entropy, sum(dy_dx))\n",
    "        # loss_value = tf.add(RMSE_loss, derivative_loss)\n",
    "        # print(loss_value)\n",
    "    print('Epoch: ', epoch+1, ' Average Train loss:', tf.get_static_value(sum(loss_array)/len(loss_array)), 'Average Val loss:', tf.get_static_value(sum(val_loss_array)/len(val_loss_array)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "batch_size_train = 100\n",
    "batch_size_val = 20\n",
    "\n",
    "def fetch_batch_train(X, y, batch_size, batch):\n",
    "    start = batch*batch_size\n",
    "    \n",
    "    X_batch = X[start:start+batch_size, :]\n",
    "    y_batch = y[start:start+batch_size]\n",
    "\n",
    "    print('shapes', X_batch.shape, y_batch.shape)\n",
    "\n",
    "    return X_batch, y_batch\n",
    "\n",
    "batch = 1\n",
    "\n",
    "X, y = shuffle(x_train, y_train, random_state = 42)\n",
    "X_batch, y_batch = fetch_batch(X, y, batch_size_train, batch)\n",
    "\n",
    "Val_X_batch, Val_y_batch = shuffle(x_test, y_test, random_state = 42)\n",
    "Val_X_batch, Val_y_batch = fetch_batch(Val_X_batch, Val_y_batch, batch_size_val, batch)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapes (5, 4) (5,)\n",
      "x_tensor shape (5, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zhenyap\\pycalphad\\pycalphad\\codegen\\callables.py:94: UserWarning: State variables in `build_callables` are not {N, P, T}, but {T}. This can lead to incorrectly calculated values if the state variables used to call the generated functions do not match the state variables used to create them. State variables can be added with the `additional_statevars` argument.\n",
      "  warnings.warn(\"State variables in `build_callables` are not {{N, P, T}}, but {}. This can lead to incorrectly \"\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"c:\\Users\\zhenyap\\Miniconda3\\envs\\calphad\\lib\\site-packages\\keras\\engine\\training.py\", line 1845, in predict_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\zhenyap\\Miniconda3\\envs\\calphad\\lib\\site-packages\\keras\\engine\\training.py\", line 1834, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\zhenyap\\Miniconda3\\envs\\calphad\\lib\\site-packages\\keras\\engine\\training.py\", line 1823, in run_step  **\n        outputs = model.predict_step(data)\n    File \"c:\\Users\\zhenyap\\Miniconda3\\envs\\calphad\\lib\\site-packages\\keras\\engine\\training.py\", line 1791, in predict_step\n        return self(x, training=False)\n    File \"c:\\Users\\zhenyap\\Miniconda3\\envs\\calphad\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\zhenyap\\AppData\\Local\\Temp\\1\\__autograph_generated_fileulffh89q.py\", line 11, in tf__call\n        output = ag__.converted_call(ag__.ld(self).crossnet_1, ((ag__.ld(x0), ag__.ld(x0)),), None, fscope)\n    File \"C:\\Users\\zhenyap\\AppData\\Local\\Temp\\1\\__autograph_generated_filekvfy79yq.py\", line 41, in tf__call\n        ag__.if_stmt(ag__.ld(self).projection_dim is None, if_body_1, else_body_1, get_state_1, set_state_1, ('prod_output',), 1)\n    File \"C:\\Users\\zhenyap\\AppData\\Local\\Temp\\1\\__autograph_generated_filekvfy79yq.py\", line 34, in if_body_1\n        prod_output = ag__.converted_call(ag__.ld(tf).matmul, (ag__.ld(x), ag__.ld(self).kernel), None, fscope)\n\n    ValueError: Exception encountered when calling layer \"liquid\" (type CalphadPhaseModel).\n    \n    in user code:\n    \n        File \"c:\\Users\\zhenyap\\pycalphad\\neural.py\", line 41, in call  *\n            output = self.crossnet_1((x0, x0))\n        File \"c:\\Users\\zhenyap\\Miniconda3\\envs\\calphad\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler  **\n            raise e.with_traceback(filtered_tb) from None\n        File \"C:\\Users\\zhenyap\\AppData\\Local\\Temp\\1\\__autograph_generated_filekvfy79yq.py\", line 41, in tf__call\n            ag__.if_stmt(ag__.ld(self).projection_dim is None, if_body_1, else_body_1, get_state_1, set_state_1, ('prod_output',), 1)\n        File \"C:\\Users\\zhenyap\\AppData\\Local\\Temp\\1\\__autograph_generated_filekvfy79yq.py\", line 34, in if_body_1\n            prod_output = ag__.converted_call(ag__.ld(tf).matmul, (ag__.ld(x), ag__.ld(self).kernel), None, fscope)\n    \n        ValueError: Exception encountered when calling layer \"polynomial_crossing\" (type PolynomialCrossing).\n        \n        in user code:\n        \n            File \"c:\\Users\\zhenyap\\Miniconda3\\envs\\calphad\\lib\\site-packages\\tensorflow_addons\\layers\\polynomial.py\", line 158, in call  *\n                prod_output = tf.matmul(x, self.kernel)\n        \n            ValueError: Dimensions must be equal, but are 4 and 1 for '{{node liquid/polynomial_crossing/MatMul}} = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false](liquid/rescaler/mul, liquid/polynomial_crossing/MatMul/ReadVariableOp)' with input shapes: [?,4], [1,1].\n        \n        \n        Call arguments received by layer \"polynomial_crossing\" (type PolynomialCrossing):\n          • inputs=('tf.Tensor(shape=(None, 4), dtype=float32)', 'tf.Tensor(shape=(None, 4), dtype=float32)')\n    \n    \n    Call arguments received by layer \"liquid\" (type CalphadPhaseModel):\n      • inputs=tf.Tensor(shape=(None, 4), dtype=float32)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\zhenyap\\pycalphad\\training_loop2.ipynb Cell 11\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/zhenyap/pycalphad/training_loop2.ipynb#ch0000010?line=21'>22</a>\u001b[0m tape\u001b[39m.\u001b[39mwatch(x_tensor)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/zhenyap/pycalphad/training_loop2.ipynb#ch0000010?line=22'>23</a>\u001b[0m \u001b[39m# print(x_tensor)\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/zhenyap/pycalphad/training_loop2.ipynb#ch0000010?line=23'>24</a>\u001b[0m predictions \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mpredict(x_tensor)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/zhenyap/pycalphad/training_loop2.ipynb#ch0000010?line=24'>25</a>\u001b[0m \u001b[39m# print(predictions)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/zhenyap/pycalphad/training_loop2.ipynb#ch0000010?line=26'>27</a>\u001b[0m dy_dx \u001b[39m=\u001b[39m tape\u001b[39m.\u001b[39mgradient(predictions, x_tensor)\n",
      "File \u001b[1;32mc:\\Users\\zhenyap\\Miniconda3\\envs\\calphad\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\1\\__autograph_generated_file2xhm_bq2.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__predict_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\1\\__autograph_generated_fileulffh89q.py:11\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m      9\u001b[0m retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mUndefinedReturnValue()\n\u001b[0;32m     10\u001b[0m x0 \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39mrescaler, (ag__\u001b[39m.\u001b[39mld(inputs),), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m---> 11\u001b[0m output \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(\u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mcrossnet_1, ((ag__\u001b[39m.\u001b[39;49mld(x0), ag__\u001b[39m.\u001b[39;49mld(x0)),), \u001b[39mNone\u001b[39;49;00m, fscope)\n\u001b[0;32m     12\u001b[0m output \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39mcrossnet_2, ((ag__\u001b[39m.\u001b[39mld(x0), ag__\u001b[39m.\u001b[39mld(output)),), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[0;32m     13\u001b[0m output \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39mcrossnet_3, ((ag__\u001b[39m.\u001b[39mld(x0), ag__\u001b[39m.\u001b[39mld(output)),), \u001b[39mNone\u001b[39;00m, fscope)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\1\\__autograph_generated_filekvfy79yq.py:41\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m     39\u001b[0m     prod_output \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(tf)\u001b[39m.\u001b[39mmatmul, (ag__\u001b[39m.\u001b[39mld(prod_output), ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39mkernel_v), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[0;32m     40\u001b[0m prod_output \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mUndefined(\u001b[39m'\u001b[39m\u001b[39mprod_output\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> 41\u001b[0m ag__\u001b[39m.\u001b[39;49mif_stmt(ag__\u001b[39m.\u001b[39;49mld(\u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mprojection_dim \u001b[39mis\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m, if_body_1, else_body_1, get_state_1, set_state_1, (\u001b[39m'\u001b[39;49m\u001b[39mprod_output\u001b[39;49m\u001b[39m'\u001b[39;49m,), \u001b[39m1\u001b[39;49m)\n\u001b[0;32m     43\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_state_2\u001b[39m():\n\u001b[0;32m     44\u001b[0m     \u001b[39mreturn\u001b[39;00m (prod_output,)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\1\\__autograph_generated_filekvfy79yq.py:34\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call.<locals>.if_body_1\u001b[1;34m()\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mif_body_1\u001b[39m():\n\u001b[0;32m     33\u001b[0m     \u001b[39mnonlocal\u001b[39;00m prod_output\n\u001b[1;32m---> 34\u001b[0m     prod_output \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(tf)\u001b[39m.\u001b[39;49mmatmul, (ag__\u001b[39m.\u001b[39;49mld(x), ag__\u001b[39m.\u001b[39;49mld(\u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mkernel), \u001b[39mNone\u001b[39;49;00m, fscope)\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"c:\\Users\\zhenyap\\Miniconda3\\envs\\calphad\\lib\\site-packages\\keras\\engine\\training.py\", line 1845, in predict_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\zhenyap\\Miniconda3\\envs\\calphad\\lib\\site-packages\\keras\\engine\\training.py\", line 1834, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\zhenyap\\Miniconda3\\envs\\calphad\\lib\\site-packages\\keras\\engine\\training.py\", line 1823, in run_step  **\n        outputs = model.predict_step(data)\n    File \"c:\\Users\\zhenyap\\Miniconda3\\envs\\calphad\\lib\\site-packages\\keras\\engine\\training.py\", line 1791, in predict_step\n        return self(x, training=False)\n    File \"c:\\Users\\zhenyap\\Miniconda3\\envs\\calphad\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\zhenyap\\AppData\\Local\\Temp\\1\\__autograph_generated_fileulffh89q.py\", line 11, in tf__call\n        output = ag__.converted_call(ag__.ld(self).crossnet_1, ((ag__.ld(x0), ag__.ld(x0)),), None, fscope)\n    File \"C:\\Users\\zhenyap\\AppData\\Local\\Temp\\1\\__autograph_generated_filekvfy79yq.py\", line 41, in tf__call\n        ag__.if_stmt(ag__.ld(self).projection_dim is None, if_body_1, else_body_1, get_state_1, set_state_1, ('prod_output',), 1)\n    File \"C:\\Users\\zhenyap\\AppData\\Local\\Temp\\1\\__autograph_generated_filekvfy79yq.py\", line 34, in if_body_1\n        prod_output = ag__.converted_call(ag__.ld(tf).matmul, (ag__.ld(x), ag__.ld(self).kernel), None, fscope)\n\n    ValueError: Exception encountered when calling layer \"liquid\" (type CalphadPhaseModel).\n    \n    in user code:\n    \n        File \"c:\\Users\\zhenyap\\pycalphad\\neural.py\", line 41, in call  *\n            output = self.crossnet_1((x0, x0))\n        File \"c:\\Users\\zhenyap\\Miniconda3\\envs\\calphad\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler  **\n            raise e.with_traceback(filtered_tb) from None\n        File \"C:\\Users\\zhenyap\\AppData\\Local\\Temp\\1\\__autograph_generated_filekvfy79yq.py\", line 41, in tf__call\n            ag__.if_stmt(ag__.ld(self).projection_dim is None, if_body_1, else_body_1, get_state_1, set_state_1, ('prod_output',), 1)\n        File \"C:\\Users\\zhenyap\\AppData\\Local\\Temp\\1\\__autograph_generated_filekvfy79yq.py\", line 34, in if_body_1\n            prod_output = ag__.converted_call(ag__.ld(tf).matmul, (ag__.ld(x), ag__.ld(self).kernel), None, fscope)\n    \n        ValueError: Exception encountered when calling layer \"polynomial_crossing\" (type PolynomialCrossing).\n        \n        in user code:\n        \n            File \"c:\\Users\\zhenyap\\Miniconda3\\envs\\calphad\\lib\\site-packages\\tensorflow_addons\\layers\\polynomial.py\", line 158, in call  *\n                prod_output = tf.matmul(x, self.kernel)\n        \n            ValueError: Dimensions must be equal, but are 4 and 1 for '{{node liquid/polynomial_crossing/MatMul}} = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false](liquid/rescaler/mul, liquid/polynomial_crossing/MatMul/ReadVariableOp)' with input shapes: [?,4], [1,1].\n        \n        \n        Call arguments received by layer \"polynomial_crossing\" (type PolynomialCrossing):\n          • inputs=('tf.Tensor(shape=(None, 4), dtype=float32)', 'tf.Tensor(shape=(None, 4), dtype=float32)')\n    \n    \n    Call arguments received by layer \"liquid\" (type CalphadPhaseModel):\n      • inputs=tf.Tensor(shape=(None, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "batch_size_train = 5\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    loss_array = []\n",
    "    val_loss_array = []\n",
    "    \n",
    "    for batch in range(len(y_batch)//batch_size_train):\n",
    "        X_batch_train, y_batch_train = fetch_batch_train(X_batch, y_batch, batch_size_train, batch)\n",
    "\n",
    "\n",
    "        with tf.GradientTape(persistent=True) as tape:\n",
    "            # print(step)\n",
    "            # x_batch_train = x_batch_train[np.newaxis].T\n",
    "            entropy = get_values('SM', 'LIQUID', X_batch_train, dbf, comps)\n",
    "            entropy = tf.convert_to_tensor(entropy, dtype=tf.float32)\n",
    "\n",
    "            x_tensor = tf.convert_to_tensor(X_batch_train, dtype=tf.float32)\n",
    "            print('x_tensor shape', x_tensor.shape)\n",
    "            y_tensor = tf.convert_to_tensor(y_batch_train, dtype=tf.float32)\n",
    "            tape.watch(x_tensor)\n",
    "            # print(x_tensor)\n",
    "            predictions = model(x_tensor, training=True)\n",
    "            # print(predictions)\n",
    "\n",
    "            dy_dx = tape.gradient(predictions, x_tensor)\n",
    "\n",
    "            RMSE_loss = tf.sqrt(tf.divide(tf.reduce_sum(tf.pow(tf.subtract(predictions, y_tensor),2.0)),tf.cast(tf.size(y_tensor), tf.float32))) \n",
    "            derivative_loss = tf.add(entropy, sum(dy_dx))\n",
    "            # print('Loss', tf.get_static_value(RMSE_loss), tf.get_static_value(derivative_loss))\n",
    "            loss_value = tf.add(RMSE_loss, derivative_loss)\n",
    "            # print(loss_value)\n",
    "            loss_array.append(loss_value)\n",
    "\n",
    "            grads = tape.gradient(loss_value, model.trainable_variables)\n",
    "            optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "    #print(grads)\n",
    "    # print('Epoch: ', epoch+1,' Average Train loss:', tf.get_static_value(sum(loss_array)/len(loss_array)))\n",
    "\n",
    "    for step, (x_batch_val, y_batch_val) in enumerate(zip(Val_X_batch, Val_y_batch)):\n",
    "        x, y = x_batch_val, y_batch_val\n",
    "        val_loss_value = get_loss(x, y, model, get_values, dbf, comps)\n",
    "        val_loss_array.append(val_loss_value)\n",
    "    print('Epoch: ', epoch+1, ' Average Train loss:', tf.get_static_value(sum(loss_array)/len(loss_array)), 'Average Val loss:', tf.get_static_value(sum(val_loss_array)/len(val_loss_array)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([4]), TensorShape([5]), TensorShape([4, 1]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.shape, y_tensor.shape, x_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[3.3296045e-02]\n",
      " [3.6291695e+01]\n",
      " [3.5599747e+01]\n",
      " [3.6237251e+01]], shape=(4, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(dy_dx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tqdm'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\zhenyap\\pycalphad\\training_loop.ipynb Cell 7\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/zhenyap/pycalphad/training_loop.ipynb#ch0000003?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtime\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/zhenyap/pycalphad/training_loop.ipynb#ch0000003?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtqdm\u001b[39;00m \u001b[39mimport\u001b[39;00m tqdm\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/zhenyap/pycalphad/training_loop.ipynb#ch0000003?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m shuffle\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/zhenyap/pycalphad/training_loop.ipynb#ch0000003?line=3'>4</a>\u001b[0m start1 \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tqdm'"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from tqdm import tqdm\n",
    "from sklearn.utils import shuffle\n",
    "start1 = time.time()\n",
    "batch_size=100\n",
    "n_epochs = 10\n",
    "model1 = model\n",
    "loss_history = []\n",
    "acc_history = []\n",
    "val_loss_history = []\n",
    "val_acc_history = []\n",
    "for epoch in range(n_epochs):\n",
    "    X, y = shuffle(x_train, y_train, random_state = epoch**2)\n",
    "    for batch in tqdm(range(len(x_train) //batch_size)):\n",
    "    \n",
    "        X_batch, y_batch = fetch_batch(X, y, batch_size, batch)\n",
    "        # X_batch, y_batch = fetch_random_batch(X, y, batch_size)\n",
    "        loss, acc = model1.train_on_batch(X_batch, y_batch)\n",
    "    \n",
    "    loss_history.append(loss)\n",
    "    acc_history.append(acc)\n",
    "    \n",
    "    # Run validtion at the end of each epoch.\n",
    "    y_pred = model1.predict(x_test)\n",
    "    val_loss, val_acc = model1.evaluate(x_test, y_test)\n",
    "    val_loss_history.append(val_loss)\n",
    "    val_acc_history.append(val_acc)\n",
    "        \n",
    "        \n",
    "    print('Epoch: %d, Train Loss %.3f, Train Acc. %.3f, Val Loss %.3f, Val Acc. %.3f' %\n",
    "\t\t\t(epoch+1, loss, acc, val_loss, val_acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('calphad')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "818be52fc3e67187423b156bcc805b3603ed8f46451ea39369ad69a186d5bd38"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
